{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "generous-middle",
   "metadata": {},
   "source": [
    "# Compute CVaR Efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-identity",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fundamental-third",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Plots\n",
    "using JuMP\n",
    "import HiGHS\n",
    "using DataFrames\n",
    "using BenchmarkTools\n",
    "using Optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-assist",
   "metadata": {},
   "source": [
    "# Document Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-nashville",
   "metadata": {},
   "source": [
    "In this document, I will explain what is CVaR. Several methods of computing CVaR and lead readers to understand what is the most efficient way to compute CVaR. \n",
    "\n",
    "###### 1 . Define distribution and precompute variables\n",
    "\n",
    "a. explain the (distribution) function which create a distribution ($d$) dataframe/object from discrete random variable ($X$) and probability mass function ($p$).\n",
    "\n",
    "b. Precompute some repeatedly used variable could be beneficial for speed and readability. We define $\\Delta X$, Psum (CDF) and $X_{1:i}^TP_{1:i}$ for some function those required these precompute values. \n",
    "\n",
    "- Iteratively summing floating point variable could lead to high floating point arithmetic precision loss.\n",
    "    - [x] Use a higher precision random variable if needed. (suggested)\n",
    "    - [ ] Use the sum function repeatedly is slow $O(N^2)$ but more accurate.\n",
    "\n",
    "###### 2 . Joint distribution VS Decomposition\n",
    "a. We here define the Primal (CVaR and neat_CVaR) and the Decomposition (CVaR_Decom) representation of CVaR.\n",
    "\n",
    "b. Then we will compare the computational efficiency of computing CVaR. We showed that compute CVaR from joint distribution is more efficient compared to via decomposition.\n",
    "- [x] Joint\n",
    "- [ ] Decomposition\n",
    "\n",
    "###### 3 . Optimize CVaR\n",
    "Last but not least we reorganized the function to compute the CVaR of a vector of **decending ordered risks** in linear time. \n",
    "\n",
    "- For Speed improvement (N $\\alpha$s)\n",
    "    - [x] Precompute values that required to solve repeatedly.\n",
    "    - [x] Solving risk in decending order could reduce time complexity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-receipt",
   "metadata": {},
   "source": [
    "# 1 . Define Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "modern-restriction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "α = 0.8\n",
    "\n",
    "X_1 = [1,1,2,2]\n",
    "X_2 = [50,60,70,80]\n",
    "\n",
    "p1j = [0.1,0.2,0.5,0.2]\n",
    "p2j = [0.5,0.3,0.1,0.1]\n",
    "\n",
    "p_1 = 0.1\n",
    "p_2 = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-scope",
   "metadata": {},
   "source": [
    "Given Conditional Distribution $X_1$ and $X_2$ and the conditional probability of $p_1$ and $p_2$. We can calculate the joint distribution $X$ as follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "documentary-radius",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Vector{Float64}:\n",
       " 0.010000000000000002\n",
       " 0.020000000000000004\n",
       " 0.05\n",
       " 0.020000000000000004\n",
       " 0.45\n",
       " 0.27\n",
       " 0.09000000000000001\n",
       " 0.09000000000000001"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [X_1; X_2]\n",
    "p = [p_1 * p1j; p_2 * p2j]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-spiritual",
   "metadata": {},
   "source": [
    "Let use a single DataFrame ($d$) instead of two Vectors ($X$ and $p$) to represent the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-dividend",
   "metadata": {},
   "source": [
    "### distribution(X,p) \n",
    "- Combine values and pmf ($X$,$p$) into a single dataframe $d$.\n",
    "- Remove values $x$ with zero probability of occuring.\n",
    "- Aggegate distribution $d$ with value $X$ by adding the Prob $Pr$ of same values.\n",
    "- Sort the distribution $d$ with values $X$ in increasing order.\n",
    "- return $d$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "enormous-elimination",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>6×2 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">X</th><th style = \"text-align: left;\">p</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0.03</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">0.07</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">50</td><td style = \"text-align: right;\">0.45</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">60</td><td style = \"text-align: right;\">0.27</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">70</td><td style = \"text-align: right;\">0.09</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">80</td><td style = \"text-align: right;\">0.09</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& X & p\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 0.03 \\\\\n",
       "\t2 & 2 & 0.07 \\\\\n",
       "\t3 & 50 & 0.45 \\\\\n",
       "\t4 & 60 & 0.27 \\\\\n",
       "\t5 & 70 & 0.09 \\\\\n",
       "\t6 & 80 & 0.09 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m6×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m X     \u001b[0m\u001b[1m p       \u001b[0m\n",
       "     │\u001b[90m Int64 \u001b[0m\u001b[90m Float64 \u001b[0m\n",
       "─────┼────────────────\n",
       "   1 │     1     0.03\n",
       "   2 │     2     0.07\n",
       "   3 │    50     0.45\n",
       "   4 │    60     0.27\n",
       "   5 │    70     0.09\n",
       "   6 │    80     0.09"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function distribution(X,p)\n",
    "    d = DataFrame(X = X, p = p)\n",
    "    d = d[d.p .> 0,:]\n",
    "    d = combine(groupby(d, [\"X\"]),df -> DataFrame(p = sum(df.p)) ) \n",
    "    sort!(d,[\"X\"]) \n",
    "    return d\n",
    "end\n",
    "d_1 = distribution(X_1,p1j)\n",
    "d_2 = distribution(X_2,p2j)\n",
    "p_cond = [p_1;p_2] \n",
    "d = distribution(X,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-travel",
   "metadata": {},
   "source": [
    "#### Preliminary 1 \n",
    "To compare the Asymptotic computational complexity between algorithms, we define $N$ as the number of values with non-zero probability that the discrete variable $X$ could take. We define $M$ as the total number of $\\alpha$s required to compute given distribution of $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-switzerland",
   "metadata": {},
   "source": [
    "# 2 . Joint vs Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-belize",
   "metadata": {},
   "source": [
    "### Define CVaR\n",
    "\n",
    "For $\\alpha \\in (0,1)$, the definition of CVaR is \n",
    "$$\\text{CVaR}_{\\alpha}(X) = \\frac{\\int_\\alpha^1 \\text{VaR}_{\\alpha'}(X) d\\alpha'}{1-\\alpha} = \\frac{\\int_0^{1-\\alpha} Q_X(\\lambda') d\\lambda'}{1-\\alpha} = \\frac{\\int_0^{1-\\alpha} F^{-1}_X(\\lambda') d\\lambda'}{1-\\alpha}$$\n",
    ". Let $\\lambda = 1-\\alpha$ we can also write them as\n",
    "$$\\text{CVaR}_{\\alpha}(X) = \\frac{\\int_\\alpha^1 \\text{VaR}_{\\alpha'}(X) d\\alpha'}{\\lambda} = \\frac{\\int_0^{\\lambda} Q_X(\\lambda') d\\lambda'}{\\lambda} = \\frac{\\int_0^{\\lambda} F^{-1}_X(\\lambda') d\\lambda'}{\\lambda}$$\n",
    "where $\\text{VaR}_{\\alpha'}(X)$ refers to the $\\alpha'$ Value of Risk of a distribution $X$, and $Q_X(\\lambda) = F^{-1}_X(\\lambda)$ refers to the $\\lambda$ inverse distribution function (quantile function) of X. Here we present the straight forward algorithm for $\\text{CVaR}_{\\alpha}(X) = \\frac{\\int_0^{\\lambda} Q_X(\\lambda') d\\lambda'}{\\lambda}$, all other primal method are in the spirit of this algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adolescent-stage",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CVaR_Vec (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CVaR function takes in a distribution d and a risk parameter alpha. \n",
    "function CVaR(d,α)\n",
    "    # Set lambda\n",
    "    λ = 1-α\n",
    "    \n",
    "    # Special Case:\n",
    "    if λ == 0\n",
    "        return minimum(d[d.p .> 0,:].X)\n",
    "    end  \n",
    "    \n",
    "    # General Cases (Take Integral over 0 to lambda) Q_X(lambda') dlambda'\n",
    "    Psum = 0\n",
    "    for i in 1:nrow(d)\n",
    "        if λ <= Psum + d.p[i]\n",
    "            return (transpose(d.X[1:i])*[d.p[1:(i-1)];λ-Psum])/λ\n",
    "        end\n",
    "        Psum = Psum + d.p[i]\n",
    "    end  \n",
    "    return (transpose(d.X)*d.p)\n",
    "end\n",
    "\n",
    "# Solve CVaR for multiple Alphas.\n",
    "function CVaR_Vec(d,Alpha)\n",
    "    return [CVaR(d,α) for α in Alpha]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b171d1",
   "metadata": {},
   "source": [
    "#### Helper function (Pre-compute Variable)\n",
    "Precompute $\\Delta X$ takes **$O(N)$-time**. Assuming $X$ is $N$ elements sorted distribution with values $\\{x_1,x_2,x_3,\\cdots,x_{N}\\}$, $\\Delta X_1 = \\min\\{X\\} = x_1$ and $\\Delta X_i = x_i - x_{i-1}$. \n",
    "\n",
    "Precompute $\\sum^{i}_{j=1}P(x_j) = F(x_i)$ Psum or CDF for $i \\in 1\\cdots N$ iteratively takes **$O(N)$-time**.\n",
    "\n",
    "Precompute $\\sum^{i}_{j=1}[ x_j \\cdot P(x_j) ] =  X_{1:i}^T P_{1:i}$ for $i \\in 1\\cdots N$ iteratively takes **$O(N)$-time**.\n",
    "\n",
    "<font color='green'>The precompute function below will precompute some repeatedly used values to speed up computation in some algorithms.</font>\n",
    "\n",
    "##### <font color='red'> Minor Issue:</font>\n",
    "- (cumulativeSum) iteratively adding Psum += i.Pr could lead to minor floating point arithmetic precision loss.\n",
    "    - [x] use variable type of higher precision (suggested)\n",
    "    - [ ] use accurateCumSum O(N^2) function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3beafa23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×10 adjoint(::Vector{Int64}) with eltype Int64:\n",
       " 1  2  3  4  5  6  7  8  9  10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This delta function is the inverse of cumsum\n",
    "function delta(V)\n",
    "    return [V[1];V[Not(1)]-V[Not(length(V))]]\n",
    "end\n",
    "\n",
    "delta(cumsum(1:10))'# test delta function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1141a14",
   "metadata": {},
   "source": [
    "### CVaR search\n",
    "$$\\lambda \\text{CVaR}_{\\alpha}(X) = \\mathbb{E}[~X ~ 1_{\\{X \\leq x_\\alpha\\}}~] ~+~ x_\\alpha(~\\lambda -\\mathbb{P}[X \\leq x_\\alpha]~) $$\n",
    "where $x_\\alpha = \\text{VaR}_{\\alpha}(X) = Q_{X}(\\lambda)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27ca4bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "search_CVaR_Vec (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CVaR_Search function takes in a distribution (d) and a vector of risk (Alpha)\n",
    "function search_CVaR(d,α)\n",
    "    # Set lambda\n",
    "    λ = 1-α\n",
    "    if λ == 0\n",
    "        return(minimum(d[d.p .> 0,:].X))\n",
    "    end\n",
    "    αi = min(searchsortedfirst(d.Psum,λ),length(d.Psum))\n",
    "    return( ( d.XTP[αi] + d.X[αi] * (λ - d.Psum[αi]) ) / λ )\n",
    "end\n",
    "\n",
    "# Solve CVaR for multiple Alphas.\n",
    "function search_CVaR_Vec(d,Alpha)\n",
    "    # Here we precompute repeatedly used values, Psum and XTP.\n",
    "    d.Psum = cumsum(d.p)\n",
    "    d.XTP = cumsum(d.X .* d.p)\n",
    "    \n",
    "    return [search_CVaR(d,α) for α in Alpha]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-implementation",
   "metadata": {},
   "source": [
    "### Neat CVaR (Piecewise Linear)\n",
    "Since $(1-\\alpha)\\cdot$CVaR$_\\alpha(X)$ is piecewise linear, we can compute CVaR as a piecewise linear function for discrete random variable $X$ as \n",
    "    $$(1-\\alpha) \\text{CVaR}_\\alpha(X) = \\int_0^{\\lambda} Q_X(\\lambda') d\\lambda' = \\sum_{i=1}^{N} \\big( \\Delta X_i \\cdot (1-\\alpha - \\sum^{i-1}_{j=1}P(x_j))_{+}\\big)$$\n",
    "    $$\\text{CVaR}_\\alpha(X) = \\frac{\\int_0^{\\lambda} Q_X(\\lambda') d\\lambda'}{\\lambda} =  \\frac{\\sum_{i=1}^{N} \\big( \\Delta X_i \\cdot (\\lambda - \\sum^{i-1}_{j=1}P(x_j))_{+} \\big)}{\\lambda}$$\n",
    "Assuming $X$ is $N$ element sorted distribution with values $\\{x_1,x_2,x_3,\\cdots,x_{N}\\}$, $\\Delta X_1 = \\min\\{X\\}$ and $\\Delta X_i = x_i - x_{i-1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "czech-grammar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neat_CVaR_Vec (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function neat_CVaR(d,α,λ=1-α) # O(N)\n",
    "    if λ == 0\n",
    "        return minimum(d[d.p .> 0,:].X)\n",
    "    else\n",
    "        return (transpose(d.ΔX)*max.(zeros(nrow(d)),λ .- d.Psum .+ d.p))/λ\n",
    "    end\n",
    "end\n",
    "\n",
    "# CVaR method to solve for multiple Alphas\n",
    "function neat_CVaR_Vec(d,Alpha)\n",
    "    d.ΔX = delta(d.X)      # O(N)\n",
    "    d.Psum = cumsum(d.p)   # O(N)\n",
    "    return [neat_CVaR(d,α) for α in Alpha]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-concern",
   "metadata": {},
   "source": [
    "To solve for $M$ amount of different $\\alpha$ risk level, the original method and the neat method is $O(NM)$, the neat method would perform faster in certain cercumstance because the factor for the $NM$ is smaller for neat method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-surprise",
   "metadata": {},
   "source": [
    "### CVaR via Decomposition\n",
    "In this section we will intorudce the decomposition method by Pflug to solve the CVaR\n",
    "$$\\text{CVaR}_{\\alpha}(X) = \\inf_Z \\{\\mathbb{E}[Z \\cdot \\text{CVaR}_{1-(1-\\alpha)Z}(X|f_i)] \\mid \\mathbb{E}[Z] = 1, 0 \\leq Z \\leq \\frac{\\mathbb{1}}{1-\\alpha}  \\}$$\n",
    "For the example above with only two possible conditions, $\\mathbb{E}[Z] = 1 \\implies z_2  = \\frac{1 - z_1 p_1}{p_2}$ and we will only require to minimize an univariate ($z_1$) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aging-amazon",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CVaR_Decom_Vec (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(z_1,α) = p_1 * z_1 * neat_CVaR(d_1,1-(1-α)*z_1) + p_2 *((1-p_1*z_1)/p_2)* neat_CVaR(d_2,1-(1-α)*((1-p_1*z_1)/p_2))\n",
    "\n",
    "function CVaR_Decom(α)\n",
    "    if α == 1\n",
    "        return min(minimum(d_1[d_1.p .> 0,:].X),minimum(d_2[d_2.p .> 0,:].X))\n",
    "    else\n",
    "        return Optim.minimum(optimize(z_1 -> f(z_1,α),0,1/(1-α),abs_tol=1e-12,rel_tol=1e-12)) \n",
    "    end\n",
    "end\n",
    "\n",
    "function CVaR_Decom_Vec(Alpha)\n",
    "    d_1.ΔX = delta(d_1.X)      # O(N)\n",
    "    d_1.Psum = cumsum(d_1.p)   # O(N)\n",
    "    d_2.ΔX = delta(d_2.X)      # O(N)\n",
    "    d_2.Psum = cumsum(d_2.p)   # O(N)\n",
    "    return [CVaR_Decom(α) for α in Alpha]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-general",
   "metadata": {},
   "source": [
    "### Speed comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "public-snapshot",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>4×2 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Alg</th><th style = \"text-align: left;\">time</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">ori</td><td style = \"text-align: right;\">0.0014564</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">search</td><td style = \"text-align: right;\">0.001073</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">neat</td><td style = \"text-align: right;\">0.0042119</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">decom</td><td style = \"text-align: right;\">0.766608</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& Alg & time\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & ori & 0.0014564 \\\\\n",
       "\t2 & search & 0.001073 \\\\\n",
       "\t3 & neat & 0.0042119 \\\\\n",
       "\t4 & decom & 0.766608 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m4×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Alg    \u001b[0m\u001b[1m time      \u001b[0m\n",
       "     │\u001b[90m String \u001b[0m\u001b[90m Float64   \u001b[0m\n",
       "─────┼───────────────────\n",
       "   1 │ ori     0.0014564\n",
       "   2 │ search  0.001073\n",
       "   3 │ neat    0.0042119\n",
       "   4 │ decom   0.766608"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Alpha = LinRange(1,0,1001)\n",
    "\n",
    "CVaR_ori = CVaR_Vec(d,Alpha)\n",
    "t_ori = @elapsed CVaR_Vec(d,Alpha)\n",
    "\n",
    "CVaR_neat = neat_CVaR_Vec(d,Alpha)\n",
    "t_neat = @elapsed neat_CVaR_Vec(d,Alpha)\n",
    "\n",
    "CVaR_search = search_CVaR_Vec(d,Alpha)\n",
    "t_search = @elapsed search_CVaR_Vec(d,Alpha)\n",
    "\n",
    "CVaR_decom = CVaR_Decom_Vec(Alpha)\n",
    "t_decom = @elapsed CVaR_Decom_Vec(Alpha)\n",
    "\n",
    "DiffNeat = DataFrame(Alg = [\"ori\";\"search\";\"neat\";\"decom\"],time = [maximum(abs.(CVaR_ori .- CVaR_neat));maximum(abs.(CVaR_search .- CVaR_neat)); 0;maximum(abs.(CVaR_decom .- CVaR_neat))])\n",
    "TimeDf = DataFrame(Alg = [\"ori\";\"search\";\"neat\";\"decom\"],time = [t_ori;t_search; t_neat;t_decom])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-spotlight",
   "metadata": {},
   "source": [
    "Both methods with joint distribution (neat and ori) outperform decomposition (decom) method by huge margin.\n",
    "\n",
    "##### Conclusion : Compute CVaR with joint distribution is faster by huge margin compare to decomposition with LP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-girlfriend",
   "metadata": {},
   "source": [
    "# 3 . Optimizes CVaR for multiple $\\alpha$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-gravity",
   "metadata": {},
   "source": [
    "### Issue of CVaR\n",
    "The CVaR algorithm above is genearlly good enough if we are solving for only one single $\\alpha$. However, there are room for improvement to the algorithm when we intend to solve many $\\alpha$s.\n",
    "\n",
    "- For the algorithm above, the computation required to solve a $\\alpha$ is $O(N)$ for $N = \\text{nrow}(d)$. Therefore solving $M = |\\alpha|$ many $\\alpha$ would require $O(MN)$ time.\n",
    "    - To reduce the computation time we could\n",
    "        - [x] Precompute and store the values we would use repeatedly (eg: CDF (Psum) and $(X^T P)$).\n",
    "        - [x] Solve $M$ risk level $\\alpha$ in $O(M+N)$-time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-lightning",
   "metadata": {},
   "source": [
    "The Fast_CVaR algorithm will takes in a vector of **<font color='red'> sorted decending order</font>** $\\alpha$s and calculate their CVaR all together. Instead of running $O(MN)$-time, it takes only $O(M+N)$-time to run. Assumed that the vector risk parameter is sorted, we will not need to seek for previous seen $i$ for the CVaR of smaller $\\lambda = 1-\\alpha$. Instead each $i$ only increment once from $1 \\cdots N$ and each $j$ only increment once from $1 \\cdots M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "brazilian-symposium",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fast_CVaR (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FastCVaR function takes in a distribution (d) and a vector of risk (Alpha)\n",
    "function Fast_CVaR(d,Alpha)\n",
    "    # Set lambda \n",
    "    Lambda = 1 .- Alpha\n",
    "    \n",
    "    M = length(Alpha)\n",
    "    N = nrow(d)\n",
    "    output = zeros(M)\n",
    "    j = 1\n",
    "    \n",
    "    # Here we precompute repeatedly used values, Psum and XTP.\n",
    "    d.Psum = cumsum(d.p)\n",
    "    d.XTP = cumsum(d.X .* d.p)\n",
    "    \n",
    "    # Special Case 1: if risk is 0 just use minimum\n",
    "    while (j <= M) && (Lambda[j] == 0)\n",
    "        output[j] = minimum(d[d.p .> 0,:].X)\n",
    "        j+=1\n",
    "    end  \n",
    "    \n",
    "    # General Case for i==1, d[i-1,:] is not valid\n",
    "    while (j <= M) && (Lambda[j] <= d.Psum[1])\n",
    "        output[j] = (d.X[1]*(Lambda[j]))/Lambda[j]\n",
    "        j+=1\n",
    "    end\n",
    "    # General Cases\n",
    "    for i in 2:N\n",
    "        while (j <= M) && (Lambda[j] <= d.Psum[i])\n",
    "            output[j] = (d.XTP[i-1] + d.X[i]*(Lambda[j] - d.Psum[i-1]))/Lambda[j]\n",
    "            j+=1\n",
    "        end\n",
    "    end  \n",
    "    \n",
    "    while (j <= M)\n",
    "        output[j] = d.XTP[N]\n",
    "        j+=1\n",
    "    end\n",
    "    \n",
    "    return output\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "worth-worth",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>5×2 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Alg</th><th style = \"text-align: left;\">time</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">ori</td><td style = \"text-align: right;\">0.0014564</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">search</td><td style = \"text-align: right;\">0.001073</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">neat</td><td style = \"text-align: right;\">0.0042119</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">decom</td><td style = \"text-align: right;\">0.766608</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">fast</td><td style = \"text-align: right;\">0.0008883</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& Alg & time\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & ori & 0.0014564 \\\\\n",
       "\t2 & search & 0.001073 \\\\\n",
       "\t3 & neat & 0.0042119 \\\\\n",
       "\t4 & decom & 0.766608 \\\\\n",
       "\t5 & fast & 0.0008883 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Alg    \u001b[0m\u001b[1m time      \u001b[0m\n",
       "     │\u001b[90m String \u001b[0m\u001b[90m Float64   \u001b[0m\n",
       "─────┼───────────────────\n",
       "   1 │ ori     0.0014564\n",
       "   2 │ search  0.001073\n",
       "   3 │ neat    0.0042119\n",
       "   4 │ decom   0.766608\n",
       "   5 │ fast    0.0008883"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CVaR_fast = Fast_CVaR(d,Alpha)\n",
    "t_fast = @elapsed Fast_CVaR(d,Alpha)\n",
    "\n",
    "append!(DiffNeat, DataFrame(Alg = [\"fast\"],time = [maximum(abs.(CVaR_fast .- CVaR_neat))]))\n",
    "append!(TimeDf, DataFrame(Alg = [\"fast\"],time = [t_fast]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-portal",
   "metadata": {},
   "source": [
    "The original CVaR_Vec is $O(MN)$-time while the Fast_CVaR is $O(M+N)$-time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-tower",
   "metadata": {},
   "source": [
    "### Slightly more time consuming test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "prostate-affairs",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>4×17 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Alg</th><th style = \"text-align: left;\">10d-A10</th><th style = \"text-align: left;\">10d-A100</th><th style = \"text-align: left;\">10d-A1000</th><th style = \"text-align: left;\">10d-A10000</th><th style = \"text-align: left;\">100d-A10</th><th style = \"text-align: left;\">100d-A100</th><th style = \"text-align: left;\">100d-A1000</th><th style = \"text-align: left;\">100d-A10000</th><th style = \"text-align: left;\">1000d-A10</th><th style = \"text-align: left;\">1000d-A100</th><th style = \"text-align: left;\">1000d-A1000</th><th style = \"text-align: left;\">1000d-A10000</th><th style = \"text-align: left;\">10000d-A10</th><th style = \"text-align: left;\">10000d-A100</th><th style = \"text-align: left;\">10000d-A1000</th><th style = \"text-align: left;\">10000d-A10000</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">ori</td><td style = \"text-align: right;\">8.46e-5</td><td style = \"text-align: right;\">0.0004345</td><td style = \"text-align: right;\">0.0027605</td><td style = \"text-align: right;\">0.0291149</td><td style = \"text-align: right;\">0.00026</td><td style = \"text-align: right;\">0.00293</td><td style = \"text-align: right;\">0.0247021</td><td style = \"text-align: right;\">0.283871</td><td style = \"text-align: right;\">0.0019236</td><td style = \"text-align: right;\">0.0239949</td><td style = \"text-align: right;\">0.262596</td><td style = \"text-align: right;\">2.54552</td><td style = \"text-align: right;\">0.0215854</td><td style = \"text-align: right;\">0.349144</td><td style = \"text-align: right;\">2.77252</td><td style = \"text-align: right;\">27.7634</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">search</td><td style = \"text-align: right;\">7.72e-5</td><td style = \"text-align: right;\">0.0001436</td><td style = \"text-align: right;\">0.0008773</td><td style = \"text-align: right;\">0.0086789</td><td style = \"text-align: right;\">2.77e-5</td><td style = \"text-align: right;\">0.0001613</td><td style = \"text-align: right;\">0.0010917</td><td style = \"text-align: right;\">0.0113639</td><td style = \"text-align: right;\">4.13e-5</td><td style = \"text-align: right;\">0.000184</td><td style = \"text-align: right;\">0.0010858</td><td style = \"text-align: right;\">0.0383549</td><td style = \"text-align: right;\">0.0006494</td><td style = \"text-align: right;\">0.0007501</td><td style = \"text-align: right;\">0.0014448</td><td style = \"text-align: right;\">0.0128809</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">neat</td><td style = \"text-align: right;\">0.0001202</td><td style = \"text-align: right;\">0.0005967</td><td style = \"text-align: right;\">0.0041401</td><td style = \"text-align: right;\">0.0441435</td><td style = \"text-align: right;\">0.0001522</td><td style = \"text-align: right;\">0.0007889</td><td style = \"text-align: right;\">0.0070909</td><td style = \"text-align: right;\">0.0668231</td><td style = \"text-align: right;\">0.0010829</td><td style = \"text-align: right;\">0.0037618</td><td style = \"text-align: right;\">0.0275989</td><td style = \"text-align: right;\">0.298015</td><td style = \"text-align: right;\">0.0117816</td><td style = \"text-align: right;\">0.0311499</td><td style = \"text-align: right;\">0.236618</td><td style = \"text-align: right;\">1.99325</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">FastT</td><td style = \"text-align: right;\">2.73e-5</td><td style = \"text-align: right;\">0.000124</td><td style = \"text-align: right;\">0.0008295</td><td style = \"text-align: right;\">0.0097037</td><td style = \"text-align: right;\">4.55e-5</td><td style = \"text-align: right;\">0.0001781</td><td style = \"text-align: right;\">0.0010285</td><td style = \"text-align: right;\">0.0080446</td><td style = \"text-align: right;\">0.0003491</td><td style = \"text-align: right;\">0.0003762</td><td style = \"text-align: right;\">0.001125</td><td style = \"text-align: right;\">0.0082921</td><td style = \"text-align: right;\">0.0025018</td><td style = \"text-align: right;\">0.0023476</td><td style = \"text-align: right;\">0.0028994</td><td style = \"text-align: right;\">0.0111897</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& Alg & 10d-A10 & 10d-A100 & 10d-A1000 & 10d-A10000 & 100d-A10 & 100d-A100 & 100d-A1000 & \\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & ori & 8.46e-5 & 0.0004345 & 0.0027605 & 0.0291149 & 0.00026 & 0.00293 & 0.0247021 & $\\dots$ \\\\\n",
       "\t2 & search & 7.72e-5 & 0.0001436 & 0.0008773 & 0.0086789 & 2.77e-5 & 0.0001613 & 0.0010917 & $\\dots$ \\\\\n",
       "\t3 & neat & 0.0001202 & 0.0005967 & 0.0041401 & 0.0441435 & 0.0001522 & 0.0007889 & 0.0070909 & $\\dots$ \\\\\n",
       "\t4 & FastT & 2.73e-5 & 0.000124 & 0.0008295 & 0.0097037 & 4.55e-5 & 0.0001781 & 0.0010285 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m4×17 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Alg    \u001b[0m\u001b[1m 10d-A10   \u001b[0m\u001b[1m 10d-A100  \u001b[0m\u001b[1m 10d-A1000 \u001b[0m\u001b[1m 10d-A10000 \u001b[0m\u001b[1m 100d-A10  \u001b[0m\u001b[1m 100d-A1\u001b[0m ⋯\n",
       "     │\u001b[90m String \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ ori     8.46e-5    0.0004345  0.0027605   0.0291149  0.00026    0.00293 ⋯\n",
       "   2 │ search  7.72e-5    0.0001436  0.0008773   0.0086789  2.77e-5    0.00016\n",
       "   3 │ neat    0.0001202  0.0005967  0.0041401   0.0441435  0.0001522  0.00078\n",
       "   4 │ FastT   2.73e-5    0.000124   0.0008295   0.0097037  4.55e-5    0.00017\n",
       "\u001b[36m                                                              11 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TimeDf = DataFrame(Alg = [\"ori\";\"search\";\"neat\";\"FastT\"])\n",
    "for N in 10 .^ [1;2;3;4] #;5\n",
    "    for M = 10 .^ [1;2;3;4] #;5\n",
    "        d2 = DataFrame(X = LinRange(1,10,N), p = 1/N )\n",
    "        Alpha = LinRange(1,0,M)\n",
    "\n",
    "        CVaR_X = CVaR_Vec(d2,Alpha)\n",
    "        t_ori = @elapsed CVaR_Vec(d2,Alpha)\n",
    "        \n",
    "        CVaR_search = search_CVaR_Vec(d2,Alpha)\n",
    "        t_search = @elapsed search_CVaR_Vec(d2,Alpha)\n",
    "        \n",
    "        CVaR_neat = neat_CVaR_Vec(d2,Alpha)\n",
    "        t_neat = @elapsed neat_CVaR_Vec(d2,Alpha)\n",
    "\n",
    "        CVaR_fast = Fast_CVaR(d2,Alpha)\n",
    "        t_fast = @elapsed Fast_CVaR(d2,Alpha)\n",
    "\n",
    "        \n",
    "        TimeDf[!,string(N)*\"d-A\"*string(M)] = [t_ori;t_search; t_neat; t_fast]\n",
    "        \n",
    "    end\n",
    "end\n",
    "TimeDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-literature",
   "metadata": {},
   "source": [
    "We can see that the CVaRfastT consistently beating all other primal CVaR method when computing large number of $M$. When $N = 10,000$ and $M=10,000$ it computes in $10,000$ CVaR risk in $<0.003$ seconds. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
